{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment Week 2 - Group 5\n",
    "\n",
    "### Cosimo Attempt\n",
    "\n",
    "Linear Regression and Logistic Regression Start for Wk2\n",
    "\n",
    "Requires coliniearity to be added or merged into the file\n",
    "Needs Either reisidual plot QQplot for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import CambiCosimo_Functions as cc\n",
    "#Some Functions to make this process easier and cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as m\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet, LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import make_scorer, roc_curve, roc_auc_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename1 = \"fraudTrain.csv\"\n",
    "df_1 = pd.read_csv(filename1)\n",
    "filename2 = \"fraudTest.csv\"\n",
    "df_2 = pd.read_csv(filename2)\n",
    "\n",
    "fraud_df = df_1.append(df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_df['txn_datetime'] =  pd.to_datetime(fraud_df['trans_date_trans_time'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "fraud_df['date_of_birth'] =  pd.to_datetime(fraud_df['dob'], format='%Y-%m-%d')\n",
    "fraud_df['year_of_birth'] = fraud_df['date_of_birth'].dt.year\n",
    "fraud_df['date_of_birth'] = fraud_df['date_of_birth'].dt.date\n",
    "\n",
    "fraud_df['txn_date'] = fraud_df['txn_datetime'].dt.date\n",
    "\n",
    "now = pd.to_datetime('now')\n",
    "fraud_df['age'] = fraud_df.apply(lambda x: now.year - x['year_of_birth'], axis = 1)\n",
    "\n",
    "fraud_df['txn_month'] = fraud_df['txn_datetime'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0: 1296675 unique values\n",
      "trans_date_trans_time: 1819551 unique values\n",
      "cc_num: 999 unique values\n",
      "merchant: 693 unique values\n",
      "category\n",
      "['misc_net' 'grocery_pos' 'entertainment' 'gas_transport' 'misc_pos'\n",
      " 'grocery_net' 'shopping_net' 'shopping_pos' 'food_dining' 'personal_care'\n",
      " 'health_fitness' 'travel' 'kids_pets' 'home']\n",
      "amt: 60616 unique values\n",
      "first: 355 unique values\n",
      "last: 486 unique values\n",
      "gender\n",
      "['F' 'M']\n",
      "street: 999 unique values\n",
      "city: 906 unique values\n",
      "state: 51 unique values\n",
      "zip: 985 unique values\n",
      "lat: 983 unique values\n",
      "long: 983 unique values\n",
      "city_pop: 891 unique values\n",
      "job: 497 unique values\n",
      "dob: 984 unique values\n",
      "trans_num: 1852394 unique values\n",
      "unix_time: 1819583 unique values\n",
      "merch_lat: 1754157 unique values\n",
      "merch_long: 1809753 unique values\n",
      "is_fraud\n",
      "[0 1]\n",
      "txn_datetime: 1819551 unique values\n",
      "date_of_birth: 984 unique values\n",
      "year_of_birth: 82 unique values\n",
      "txn_date: 730 unique values\n",
      "age: 82 unique values\n",
      "txn_month\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12]\n"
     ]
    }
   ],
   "source": [
    "#(dataframe, max number of unique values to show)\n",
    "cc.UniqueValues(fraud_df,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create target lables\n",
    "#target 1 will be the continous variable for linear regression: amt\n",
    "fraud_df['Target1'] = fraud_df['amt']\n",
    "#target 2 will be a binary classification variable for logistic regression: is_fraud\n",
    "fraud_df['Target2'] = fraud_df['is_fraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#review the distribution of the target variables\n",
    "fraud_df['Target1'].plot.box()\n",
    "plt.title('Target1:Credit Card Charge Amount')\n",
    "plt.xlabel('Box Plot')\n",
    "plt.ylabel('Amount $')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The distribution of the amt is very wide with a small inter quartile, therefore\n",
    "#we change Tartet 1 to the natural log of the amt to transform it to a feature \n",
    "#that has a tighter distribution\n",
    "fraud_df['Target1'] = fraud_df['log_amt'] = fraud_df['amt'].apply(lambda x: m.log(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#review the distribution of the target variables\n",
    "fraud_df['Target1'].plot.box()\n",
    "plt.title('Target1:Credit Card Charge Natural Log of Amount')\n",
    "plt.xlabel('Box Plot')\n",
    "plt.ylabel('Log(Amount $)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prevalence of the positive class for Target2: 0.005\n"
     ]
    }
   ],
   "source": [
    "#Review the prevalence of the positive class for target2\n",
    "print('Prevalence of the positive class for Target2: {:.3f}'.format(cc.calc_prevalence(fraud_df['Target2'].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a lis to hold our categorical columns and one to hold our numerical columns\n",
    "cat_col = ['category','gender','txn_month']\n",
    "num_col_linr = ['age']\n",
    "num_col_logr = ['age','log_amt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "txn_month    0\n",
      "gender       0\n",
      "category     0\n",
      "dtype: int64\n",
      "age    0\n",
      "dtype: int64\n",
      "log_amt    0\n",
      "age        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#make sure there are no missing values \n",
    "print(fraud_df[cat_col].isnull().sum().sort_values(ascending = False).head(50))\n",
    "print(fraud_df[num_col_linr].isnull().sum().sort_values(ascending = False).head(50))\n",
    "print(fraud_df[num_col_logr].isnull().sum().sort_values(ascending = False).head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In order for categorical columns to work we have to one hot encode them\n",
    "if len(cat_col)>0: \n",
    "    cat_onehotencode = pd.get_dummies(fraud_df[cat_col],drop_first = True)\n",
    "    cat_col_onehotencode = list(cat_onehotencode.columns)\n",
    "    fraud_df = pd.concat([fraud_df,cat_onehotencode], axis = 1)\n",
    "\n",
    "else:\n",
    "    cols_cate_onehotencode = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the Features and Create input lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of features: 16\n",
      "Numerical Features: 1\n",
      "Categorical Features: 15\n"
     ]
    }
   ],
   "source": [
    "print('Total number of features: {}'.format(len(num_col_linr + cat_col_onehotencode)))\n",
    "print('Numerical Features: {}'.format(len(num_col_linr)))\n",
    "print('Categorical Features: {}'.format(len(cat_col_onehotencode)))\n",
    "input_col = (num_col_linr + cat_col_onehotencode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build Training/Validation/Test Samples \n",
    "#(dataframe,randomseed,train split)\n",
    "train,valid,test = cc.Train_Valid_Test_Split(fraud_df[input_col +['Target1']],12,.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All samples (n = 1,852,394) accounted for.\n"
     ]
    }
   ],
   "source": [
    "plt.figure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.hist(train['Target1'], alpha=0.5, label='Train',density=True)\n",
    "plt.hist(valid['Target1'], alpha=0.5, label='Valid',density=True)\n",
    "plt.hist(test['Target1'], alpha=0.5, label='Test',density=True)\n",
    "plt.legend(loc='upper right')\n",
    "plt.title = ('log(amt) Distribution in Split Datasets')\n",
    "plt.xlabel('log(amt)')\n",
    "plt.ylabel('Fraud Frequency')\n",
    "plt.show()\n",
    "\n",
    "#check all records are accounted for\n",
    "print('All samples (n = {:0,d}) accounted for.'.format(len(fraud_df)))\n",
    "assert len(fraud_df) == (len(test)+len(valid)+len(train)),'math didnt work'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the X and y matrices for models\n",
    "X_train = train[input_col].values\n",
    "X_valid = valid[input_col].values\n",
    "X_test = test[input_col].values\n",
    "\n",
    "x_model = fraud_df[input_col].values\n",
    "\n",
    "y_train = train['Target1'].values\n",
    "y_valid = valid['Target1'].values\n",
    "y_test = test['Target1'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This creates scalars in order to scale the data so each variable is of similar size.\n",
    "scaler  = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# transform our data matrices - this applies our scalar and scales the matrices for training and validation data\n",
    "X_train_tf = scaler.transform(X_train)\n",
    "X_valid_tf = scaler.transform(X_valid)\n",
    "X_test_tf = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on ElasticNet in module sklearn.linear_model._coordinate_descent object:\n",
      "\n",
      "class ElasticNet(sklearn.base.MultiOutputMixin, sklearn.base.RegressorMixin, sklearn.linear_model._base.LinearModel)\n",
      " |  ElasticNet(alpha=1.0, *, l1_ratio=0.5, fit_intercept=True, normalize=False, precompute=False, max_iter=1000, copy_X=True, tol=0.0001, warm_start=False, positive=False, random_state=None, selection='cyclic')\n",
      " |  \n",
      " |  Linear regression with combined L1 and L2 priors as regularizer.\n",
      " |  \n",
      " |  Minimizes the objective function::\n",
      " |  \n",
      " |          1 / (2 * n_samples) * ||y - Xw||^2_2\n",
      " |          + alpha * l1_ratio * ||w||_1\n",
      " |          + 0.5 * alpha * (1 - l1_ratio) * ||w||^2_2\n",
      " |  \n",
      " |  If you are interested in controlling the L1 and L2 penalty\n",
      " |  separately, keep in mind that this is equivalent to::\n",
      " |  \n",
      " |          a * L1 + b * L2\n",
      " |  \n",
      " |  where::\n",
      " |  \n",
      " |          alpha = a + b and l1_ratio = a / (a + b)\n",
      " |  \n",
      " |  The parameter l1_ratio corresponds to alpha in the glmnet R package while\n",
      " |  alpha corresponds to the lambda parameter in glmnet. Specifically, l1_ratio\n",
      " |  = 1 is the lasso penalty. Currently, l1_ratio <= 0.01 is not reliable,\n",
      " |  unless you supply your own sequence of alpha.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <elastic_net>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  alpha : float, default=1.0\n",
      " |      Constant that multiplies the penalty terms. Defaults to 1.0.\n",
      " |      See the notes for the exact mathematical meaning of this\n",
      " |      parameter. ``alpha = 0`` is equivalent to an ordinary least square,\n",
      " |      solved by the :class:`LinearRegression` object. For numerical\n",
      " |      reasons, using ``alpha = 0`` with the ``Lasso`` object is not advised.\n",
      " |      Given this, you should use the :class:`LinearRegression` object.\n",
      " |  \n",
      " |  l1_ratio : float, default=0.5\n",
      " |      The ElasticNet mixing parameter, with ``0 <= l1_ratio <= 1``. For\n",
      " |      ``l1_ratio = 0`` the penalty is an L2 penalty. ``For l1_ratio = 1`` it\n",
      " |      is an L1 penalty.  For ``0 < l1_ratio < 1``, the penalty is a\n",
      " |      combination of L1 and L2.\n",
      " |  \n",
      " |  fit_intercept : bool, default=True\n",
      " |      Whether the intercept should be estimated or not. If ``False``, the\n",
      " |      data is assumed to be already centered.\n",
      " |  \n",
      " |  normalize : bool, default=False\n",
      " |      This parameter is ignored when ``fit_intercept`` is set to False.\n",
      " |      If True, the regressors X will be normalized before regression by\n",
      " |      subtracting the mean and dividing by the l2-norm.\n",
      " |      If you wish to standardize, please use\n",
      " |      :class:`sklearn.preprocessing.StandardScaler` before calling ``fit``\n",
      " |      on an estimator with ``normalize=False``.\n",
      " |  \n",
      " |  precompute : bool or array-like of shape (n_features, n_features),                 default=False\n",
      " |      Whether to use a precomputed Gram matrix to speed up\n",
      " |      calculations. The Gram matrix can also be passed as argument.\n",
      " |      For sparse input this option is always ``True`` to preserve sparsity.\n",
      " |  \n",
      " |  max_iter : int, default=1000\n",
      " |      The maximum number of iterations\n",
      " |  \n",
      " |  copy_X : bool, default=True\n",
      " |      If ``True``, X will be copied; else, it may be overwritten.\n",
      " |  \n",
      " |  tol : float, default=1e-4\n",
      " |      The tolerance for the optimization: if the updates are\n",
      " |      smaller than ``tol``, the optimization code checks the\n",
      " |      dual gap for optimality and continues until it is smaller\n",
      " |      than ``tol``.\n",
      " |  \n",
      " |  warm_start : bool, default=False\n",
      " |      When set to ``True``, reuse the solution of the previous call to fit as\n",
      " |      initialization, otherwise, just erase the previous solution.\n",
      " |      See :term:`the Glossary <warm_start>`.\n",
      " |  \n",
      " |  positive : bool, default=False\n",
      " |      When set to ``True``, forces the coefficients to be positive.\n",
      " |  \n",
      " |  random_state : int, RandomState instance, default=None\n",
      " |      The seed of the pseudo random number generator that selects a random\n",
      " |      feature to update. Used when ``selection`` == 'random'.\n",
      " |      Pass an int for reproducible output across multiple function calls.\n",
      " |      See :term:`Glossary <random_state>`.\n",
      " |  \n",
      " |  selection : {'cyclic', 'random'}, default='cyclic'\n",
      " |      If set to 'random', a random coefficient is updated every iteration\n",
      " |      rather than looping over features sequentially by default. This\n",
      " |      (setting to 'random') often leads to significantly faster convergence\n",
      " |      especially when tol is higher than 1e-4.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  coef_ : ndarray of shape (n_features,) or (n_targets, n_features)\n",
      " |      parameter vector (w in the cost function formula)\n",
      " |  \n",
      " |  sparse_coef_ : sparse matrix of shape (n_features, 1) or             (n_targets, n_features)\n",
      " |      ``sparse_coef_`` is a readonly property derived from ``coef_``\n",
      " |  \n",
      " |  intercept_ : float or ndarray of shape (n_targets,)\n",
      " |      independent term in decision function.\n",
      " |  \n",
      " |  n_iter_ : list of int\n",
      " |      number of iterations run by the coordinate descent solver to reach\n",
      " |      the specified tolerance.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.linear_model import ElasticNet\n",
      " |  >>> from sklearn.datasets import make_regression\n",
      " |  \n",
      " |  >>> X, y = make_regression(n_features=2, random_state=0)\n",
      " |  >>> regr = ElasticNet(random_state=0)\n",
      " |  >>> regr.fit(X, y)\n",
      " |  ElasticNet(random_state=0)\n",
      " |  >>> print(regr.coef_)\n",
      " |  [18.83816048 64.55968825]\n",
      " |  >>> print(regr.intercept_)\n",
      " |  1.451...\n",
      " |  >>> print(regr.predict([[0, 0]]))\n",
      " |  [1.451...]\n",
      " |  \n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  To avoid unnecessary memory duplication the X argument of the fit method\n",
      " |  should be directly passed as a Fortran-contiguous numpy array.\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  ElasticNetCV : Elastic net model with best model selection by\n",
      " |      cross-validation.\n",
      " |  SGDRegressor: implements elastic net regression with incremental training.\n",
      " |  SGDClassifier: implements logistic regression with elastic net penalty\n",
      " |      (``SGDClassifier(loss=\"log\", penalty=\"elasticnet\")``).\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      ElasticNet\n",
      " |      sklearn.base.MultiOutputMixin\n",
      " |      sklearn.base.RegressorMixin\n",
      " |      sklearn.linear_model._base.LinearModel\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, alpha=1.0, *, l1_ratio=0.5, fit_intercept=True, normalize=False, precompute=False, max_iter=1000, copy_X=True, tol=0.0001, warm_start=False, positive=False, random_state=None, selection='cyclic')\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None, check_input=True)\n",
      " |      Fit model with coordinate descent.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {ndarray, sparse matrix} of (n_samples, n_features)\n",
      " |          Data\n",
      " |      \n",
      " |      y : {ndarray, sparse matrix} of shape (n_samples,) or             (n_samples, n_targets)\n",
      " |          Target. Will be cast to X's dtype if necessary\n",
      " |      \n",
      " |      sample_weight : float or array-like of shape (n_samples,), default=None\n",
      " |          Sample weight.\n",
      " |      \n",
      " |      check_input : bool, default=True\n",
      " |          Allow to bypass several input checking.\n",
      " |          Don't use this parameter unless you know what you do.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      \n",
      " |      Coordinate descent is an algorithm that considers each column of\n",
      " |      data at a time hence it will automatically convert the X input\n",
      " |      as a Fortran-contiguous numpy array if necessary.\n",
      " |      \n",
      " |      To avoid memory re-allocation it is advised to allocate the\n",
      " |      initial data in memory directly using that format.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  path = enet_path(X, y, *, l1_ratio=0.5, eps=0.001, n_alphas=100, alphas=None, precompute='auto', Xy=None, copy_X=True, coef_init=None, verbose=False, return_n_iter=False, positive=False, check_input=True, **params)\n",
      " |      Compute elastic net path with coordinate descent.\n",
      " |      \n",
      " |      The elastic net optimization function varies for mono and multi-outputs.\n",
      " |      \n",
      " |      For mono-output tasks it is::\n",
      " |      \n",
      " |          1 / (2 * n_samples) * ||y - Xw||^2_2\n",
      " |          + alpha * l1_ratio * ||w||_1\n",
      " |          + 0.5 * alpha * (1 - l1_ratio) * ||w||^2_2\n",
      " |      \n",
      " |      For multi-output tasks it is::\n",
      " |      \n",
      " |          (1 / (2 * n_samples)) * ||Y - XW||^Fro_2\n",
      " |          + alpha * l1_ratio * ||W||_21\n",
      " |          + 0.5 * alpha * (1 - l1_ratio) * ||W||_Fro^2\n",
      " |      \n",
      " |      Where::\n",
      " |      \n",
      " |          ||W||_21 = \\sum_i \\sqrt{\\sum_j w_{ij}^2}\n",
      " |      \n",
      " |      i.e. the sum of norm of each row.\n",
      " |      \n",
      " |      Read more in the :ref:`User Guide <elastic_net>`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          Training data. Pass directly as Fortran-contiguous data to avoid\n",
      " |          unnecessary memory duplication. If ``y`` is mono-output then ``X``\n",
      " |          can be sparse.\n",
      " |      \n",
      " |      y : {array-like, sparse matrix} of shape (n_samples,) or         (n_samples, n_outputs)\n",
      " |          Target values.\n",
      " |      \n",
      " |      l1_ratio : float, default=0.5\n",
      " |          Number between 0 and 1 passed to elastic net (scaling between\n",
      " |          l1 and l2 penalties). ``l1_ratio=1`` corresponds to the Lasso.\n",
      " |      \n",
      " |      eps : float, default=1e-3\n",
      " |          Length of the path. ``eps=1e-3`` means that\n",
      " |          ``alpha_min / alpha_max = 1e-3``.\n",
      " |      \n",
      " |      n_alphas : int, default=100\n",
      " |          Number of alphas along the regularization path.\n",
      " |      \n",
      " |      alphas : ndarray, default=None\n",
      " |          List of alphas where to compute the models.\n",
      " |          If None alphas are set automatically.\n",
      " |      \n",
      " |      precompute : 'auto', bool or array-like of shape (n_features, n_features),                 default='auto'\n",
      " |          Whether to use a precomputed Gram matrix to speed up\n",
      " |          calculations. If set to ``'auto'`` let us decide. The Gram\n",
      " |          matrix can also be passed as argument.\n",
      " |      \n",
      " |      Xy : array-like of shape (n_features,) or (n_features, n_outputs),         default=None\n",
      " |          Xy = np.dot(X.T, y) that can be precomputed. It is useful\n",
      " |          only when the Gram matrix is precomputed.\n",
      " |      \n",
      " |      copy_X : bool, default=True\n",
      " |          If ``True``, X will be copied; else, it may be overwritten.\n",
      " |      \n",
      " |      coef_init : ndarray of shape (n_features, ), default=None\n",
      " |          The initial values of the coefficients.\n",
      " |      \n",
      " |      verbose : bool or int, default=False\n",
      " |          Amount of verbosity.\n",
      " |      \n",
      " |      return_n_iter : bool, default=False\n",
      " |          Whether to return the number of iterations or not.\n",
      " |      \n",
      " |      positive : bool, default=False\n",
      " |          If set to True, forces coefficients to be positive.\n",
      " |          (Only allowed when ``y.ndim == 1``).\n",
      " |      \n",
      " |      check_input : bool, default=True\n",
      " |          Skip input validation checks, including the Gram matrix when provided\n",
      " |          assuming there are handled by the caller when check_input=False.\n",
      " |      \n",
      " |      **params : kwargs\n",
      " |          Keyword arguments passed to the coordinate descent solver.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      alphas : ndarray of shape (n_alphas,)\n",
      " |          The alphas along the path where models are computed.\n",
      " |      \n",
      " |      coefs : ndarray of shape (n_features, n_alphas) or             (n_outputs, n_features, n_alphas)\n",
      " |          Coefficients along the path.\n",
      " |      \n",
      " |      dual_gaps : ndarray of shape (n_alphas,)\n",
      " |          The dual gaps at the end of the optimization for each alpha.\n",
      " |      \n",
      " |      n_iters : list of int\n",
      " |          The number of iterations taken by the coordinate descent optimizer to\n",
      " |          reach the specified tolerance for each alpha.\n",
      " |          (Is returned when ``return_n_iter`` is set to True).\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      MultiTaskElasticNet\n",
      " |      MultiTaskElasticNetCV\n",
      " |      ElasticNet\n",
      " |      ElasticNetCV\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For an example, see\n",
      " |      :ref:`examples/linear_model/plot_lasso_coordinate_descent_path.py\n",
      " |      <sphx_glr_auto_examples_linear_model_plot_lasso_coordinate_descent_path.py>`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  sparse_coef_\n",
      " |      sparse representation of the fitted ``coef_``\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.MultiOutputMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.RegressorMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the coefficient of determination R^2 of the prediction.\n",
      " |      \n",
      " |      The coefficient R^2 is defined as (1 - u/v), where u is the residual\n",
      " |      sum of squares ((y_true - y_pred) ** 2).sum() and v is the total\n",
      " |      sum of squares ((y_true - y_true.mean()) ** 2).sum().\n",
      " |      The best possible score is 1.0 and it can be negative (because the\n",
      " |      model can be arbitrarily worse). A constant model that always\n",
      " |      predicts the expected value of y, disregarding the input features,\n",
      " |      would get a R^2 score of 0.0.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples. For some estimators this may be a\n",
      " |          precomputed kernel matrix or a list of generic objects instead,\n",
      " |          shape = (n_samples, n_samples_fitted),\n",
      " |          where n_samples_fitted is the number of\n",
      " |          samples used in the fitting for the estimator.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True values for X.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          R^2 of self.predict(X) wrt. y.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The R2 score used when calling ``score`` on a regressor uses\n",
      " |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      " |      with default value of :func:`~sklearn.metrics.r2_score`.\n",
      " |      This influences the ``score`` method of all the multioutput\n",
      " |      regressors (except for\n",
      " |      :class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.linear_model._base.LinearModel:\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict using the linear model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like or sparse matrix, shape (n_samples, n_features)\n",
      " |          Samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : array, shape (n_samples,)\n",
      " |          Returns predicted values.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ElasticNet())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Baseline Model\n",
    "linr=LinearRegression(n_jobs=-1)\n",
    "linr.fit(X_train_tf, y_train)\n",
    "\n",
    "linr_y_valid_pred = linr.predict(X_valid_tf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linr.score(X_train_tf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 1.53\n",
      "Coefficient of determination: 0.20\n"
     ]
    }
   ],
   "source": [
    "# The mean squared error\n",
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_valid, linr_y_valid_pred))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_valid, linr_y_valid_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a model using regularization\n",
    "#ElasticNet allows for a combination of L1 and L2 regularization\n",
    "enet = ElasticNet(random_state=12)\n",
    "enet.fit(X_train_tf, y_train)\n",
    "\n",
    "enet_y_valid_pred = enet.predict(X_valid_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 1.92\n",
      "Coefficient of determination: -0.00\n"
     ]
    }
   ],
   "source": [
    "# The mean squared error\n",
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_valid, enet_y_valid_pred))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_valid, enet_y_valid_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the Features and Create input lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of features: 17\n",
      "Numerical Features: 2\n",
      "Categorical Features: 15\n"
     ]
    }
   ],
   "source": [
    "print('Total number of features: {}'.format(len(num_col_logr + cat_col_onehotencode)))\n",
    "print('Numerical Features: {}'.format(len(num_col_logr)))\n",
    "print('Categorical Features: {}'.format(len(cat_col_onehotencode)))\n",
    "input_col = (num_col_logr + cat_col_onehotencode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build Training/Validation/Test Samples \n",
    "#(dataframe,randomseed,train split)\n",
    "train,valid,test = cc.Train_Valid_Test_Split(fraud_df[input_col +['Target2']],12,.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target2 checks:\n",
      "Test prevalence(n = 277,859):0.005\n",
      "Valid prevalence(n = 277,859):0.005\n",
      "Train all prevalence(n = 1,296,676):0.005\n",
      "All samples (n = 1,852,394) accounted for.\n"
     ]
    }
   ],
   "source": [
    "# check the prevalence of each subset for target 2\n",
    "print('Target2 checks:')\n",
    "print('Test prevalence(n = {:0,d}):{:.3f}'.format(len(test),cc.calc_prevalence(test.Target2.values)))\n",
    "print('Valid prevalence(n = {:0,d}):{:.3f}'.format(len(valid),cc.calc_prevalence(valid.Target2.values)))\n",
    "print('Train all prevalence(n = {:0,d}):{:.3f}'.format(len(train),cc.calc_prevalence(train.Target2.values)))\n",
    "\n",
    "#check all records are accounted for\n",
    "print('All samples (n = {:0,d}) accounted for.'.format(len(fraud_df)))\n",
    "assert len(fraud_df) == (len(test)+len(valid)+len(train)),'math didnt work'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balance Method Used is  Sub\n",
      "Train balanced prevalence(n = 13,480):0.500\n"
     ]
    }
   ],
   "source": [
    "#(dataframe, 'Sub' or 'Over',output or target label)\n",
    "train_bal = cc.balance_train_df(train,'Sub','Target2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the X and y matrices for models\n",
    "X_train = train_bal[input_col].values\n",
    "X_valid = valid[input_col].values\n",
    "X_test = test[input_col].values\n",
    "\n",
    "y_train = train_bal['Target2'].values\n",
    "y_valid = valid['Target2'].values\n",
    "y_test = test['Target2'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This creates scalars in order to scale the data so each variable is of similar size.\n",
    "scaler  = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# transform our data matrices - this applies our scalar and scales the matrices for training and validation data\n",
    "X_train_tf = scaler.transform(X_train)\n",
    "X_valid_tf = scaler.transform(X_valid)\n",
    "X_test_tf = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_scoring = make_scorer(roc_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Baseline Model\n",
    "lr=LogisticRegression(random_state = 12)\n",
    "\n",
    "lr.fit(X_train_tf, y_train)\n",
    "\n",
    "y_train_preds = lr.predict_proba(X_train_tf)[:,1]\n",
    "y_valid_preds = lr.predict_proba(X_valid_tf)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 720 candidates, totalling 2160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 816 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done 2160 out of 2160 | elapsed:   13.8s finished\n",
      "C:\\Users\\ccambi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.02, 'dual': False, 'fit_intercept': True, 'max_iter': 10, 'n_jobs': -1, 'penalty': 'l1', 'solver': 'saga', 'warm_start': False}\n",
      "Baseline Logistic Regression\n",
      "Training AUC:0.848\n",
      "Validation AUC:0.855\n",
      "Optimized Logistic Regression\n",
      "Training AUC:0.845\n",
      "Validation AUC:0.853\n"
     ]
    }
   ],
   "source": [
    "#Create grid Optimized Model\n",
    "\n",
    "#C\n",
    "C = [0.02,1.2,2]\n",
    "#dual\n",
    "dual = [False,True]\n",
    "# fit_intercept \n",
    "fit_intercept = [False,True]\n",
    "#max_iter\n",
    "max_iter = [10,50,100]\n",
    "#n_jobs\n",
    "n_jobs = [-1]\n",
    "#penalty\n",
    "penalty = ['l1', 'l2']\n",
    "#solver \n",
    "solver = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "#warm_start\n",
    "warm_start = [False,True]\n",
    "\n",
    "#param_grid\n",
    "\n",
    "param_grid_lr = {'C':C,\n",
    "                'dual':dual,\n",
    "                'max_iter':max_iter,\n",
    "                'fit_intercept':fit_intercept,\n",
    "                'n_jobs':n_jobs,\n",
    "                'penalty':penalty,\n",
    "                'solver':solver,\n",
    "                'warm_start':warm_start}\n",
    "\n",
    "#print(full_grid_lr)\n",
    "\n",
    "\n",
    "# create the cross-validation by grid method\n",
    "lr_grid = GridSearchCV(estimator = lr, param_grid = param_grid_lr, \n",
    "                            cv = 3, scoring=auc_scoring,verbose = 1, n_jobs = -1, \n",
    "                            error_score=0)\n",
    "\n",
    "# fit the grid search model (this will take a few minutes)\n",
    "lr_grid.fit(X_train_tf, y_train)\n",
    "\n",
    "print(lr_grid.best_params_)\n",
    "thresh = 0.5\n",
    "\n",
    "print('Baseline Logistic Regression')\n",
    "lr_train_base_auc = roc_auc_score(y_train, y_train_preds)\n",
    "lr_valid_base_auc = roc_auc_score(y_valid, y_valid_preds)\n",
    "\n",
    "print('Training AUC:{:.3f}'.format(lr_train_base_auc))\n",
    "print('Validation AUC:{:.3f}'.format(lr_valid_base_auc))\n",
    "\n",
    "print('Optimized Logistic Regression')\n",
    "y_train_preds_grid = lr_grid.best_estimator_.predict_proba(X_train_tf)[:,1]\n",
    "y_valid_preds_grid = lr_grid.best_estimator_.predict_proba(X_valid_tf)[:,1]\n",
    "\n",
    "lr_train_opt_auc = roc_auc_score(y_train, y_train_preds_grid)\n",
    "lr_valid_opt_auc = roc_auc_score(y_valid, y_valid_preds_grid)\n",
    "\n",
    "print('Training AUC:{:.3f}'.format(lr_train_opt_auc))\n",
    "print('Validation AUC:{:.3f}'.format(lr_valid_opt_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Training:\n",
      "AUC:0.845\n",
      "accuracy:0.752\n",
      "recall:0.740\n",
      "precision:0.758\n",
      "specificity:0.763\n",
      "prevalence:0.500\n",
      " \n",
      "LR Validation:\n",
      "AUC:0.853\n",
      "accuracy:0.760\n",
      "recall:0.753\n",
      "precision:0.016\n",
      "specificity:0.760\n",
      "prevalence:0.005\n",
      " \n",
      "LR Test:\n",
      "AUC:0.844\n",
      "accuracy:0.760\n",
      "recall:0.736\n",
      "precision:0.016\n",
      "specificity:0.760\n",
      "prevalence:0.005\n",
      " \n"
     ]
    }
   ],
   "source": [
    "y_test_preds_grid = lr_grid.best_estimator_.predict_proba(X_test_tf)[:,1]\n",
    "\n",
    "print('LR Training:')\n",
    "train_auc, train_accuracy, train_recall, train_precision, train_specificity = cc.print_report(y_train,y_train_preds_grid, thresh)\n",
    "print('LR Validation:')\n",
    "valid_auc, valid_accuracy, valid_recall, valid_precision, valid_specificity = cc.print_report(y_valid,y_valid_preds_grid, thresh)\n",
    "print('LR Test:')\n",
    "test_auc, test_accuracy, test_recall, test_precision, test_specificity = cc.print_report(y_test,y_test_preds_grid, thresh)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
